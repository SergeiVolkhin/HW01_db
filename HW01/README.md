# ETL-проект: Загрузка CSV в 3НФ (PostgreSQL)

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://python.org)
[![Database](https://img.shields.io/badge/database-PostgreSQL-blue.svg)](https://www.postgresql.org/)
[![Linter](https://img.shields.io/badge/linter-pylint-yellowgreen.svg)](https://www.pylint.org/)
[![Typing](https://img.shields.io/badge/typing-mypy-blue.svg)](http://mypy-lang.org/)

Это учебный проект, демонстрирующий навыки нормализации БД и построения ETL-процесса. Скрипты на Python берут "грязные", денормализованные CSV-файлы, очищают их, трансформируют и загружают в базу данных PostgreSQL, приведенную к **Третьей нормальной форме (3НФ)**.

Проект состоит из двух этапов, которые запускаются последовательно:
1.  **Шаг 1 (`etl_1.py`):** Загрузка таблиц-справочников (Dimensions).
2.  **Шаг 2 (`etl_2.py`):** Загрузка таблиц фактов (Facts).

##  Основные возможности

* **Нормализация:** Исходные данные разложены в 3НФ (15 таблиц), что исключает избыточность и обеспечивает целостность.
* **ETL-скрипты:** Два Python-скрипта (на `pandas` и `sqlalchemy`) выполняют полный цикл Extract, Transform, Load.
* **Идемпотентность:** Скрипты можно безопасно запускать повторно. Они не будут создавать дубликаты и загрузят только новые данные.
* **Транзакционность:** Загрузка "фактов" (Шаг 2) обернута в единую транзакцию. Если на полпути произойдет сбой (например, нарушение Foreign Key), вся транзакция откатится, не оставляя "мусора" в БД.

## Структура проекта

```
HW01_db/
│
├── data/                      # Исходные CSV-файлы
│   ├── customer.csv           # Данные о клиентах
│   └── transaction.csv        # Данные о транзакциях
│
├── schema/                    # Схема базы данных
│   ├── dbdiagram.txt          # Описание схемы для dbdiagram.io
│   ├── Scheme.jpg             # Визуализация схемы БД
│   ├── Scheme.sql             # DDL-скрипт для создания таблиц
│   └── Описание нормализации.docx  # Документ с описанием процесса нормализации
│
├── reports/                 # Выгрузка данных из БД
│   ├── сustomers.jpg          # Скриншот таблицы customers
│   ├── сustomers.sql          # SQL-скрипт для выгрузки customers
│   ├── transaction.jpg        # Скриншот таблицы transaction
│   └── transaction.sql        # SQL-скрипт для выгрузки transaction
│
├── etl_1.py                   # Шаг 1: Загрузка справочников
├── etl_2.py                   # Шаг 2: Загрузка основных таблиц
├── run_etl.py                 # Оркестратор: запускает оба ETL-скрипта
│
├── requirements.txt           # Зависимости проекта
├── .env.example               # Пример файла с переменными окружения
├── .gitignore                 # Файлы, игнорируемые Git
└── README.md                  # Документация проекта
```

## Установка и запуск

Для запуска проекта на локальной машине выполните следующие шаги:

1.  **Клонируйте репозиторий:**
    ```bash
    git clone https://github.com/SergeiVolkhin/HW01_db.git
    cd HW01_db
    ```

2.  **Создайте и активируйте виртуальное окружение:**
    * На Windows:
        ```bash
        python -m venv .venv
        .\.venv\Scripts\activate
        ```

3.  **Установите зависимости:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Настройте подключение к БД:**
    Создайте файл `.env` в корне проекта (можете скопировать `.env.example`) и пропишите в нем свой URL для подключения к PostgreSQL:
    ```ini
    # .env
    DB_URL="postgresql+psycopg2://USER:PASSWORD@HOST:PORT/DATABASE"
    ```

5.  **Выполните миграцию (DDL):**
    Перед первым запуском скриптов необходимо создать структуру таблиц. Выполните содержимое файла `schema/Scheme.sql` в вашей базе данных.

6.  **Запустите ETL-процесс:**
    Скрипт-оркестратор последовательно запустит Шаг 1 и Шаг 2.
    ```bash
    python run_etl.py
    ```

## Технологии

* **Python 3.10+** — основной язык программирования
* **pandas** — обработка и трансформация данных
* **SQLAlchemy** — ORM для работы с PostgreSQL
* **psycopg2** — драйвер PostgreSQL
* **python-dotenv** — управление переменными окружения
* **pylint, mypy** — линтинг и статическая типизация

## Автор

Проект разработан в рамках учебного курса по базам данных.
